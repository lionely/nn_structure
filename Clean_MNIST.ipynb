{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QIfQ6vcSsCFU"
   },
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l0cm2wFgsCFZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ripser import Rips\n",
    "import persim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVxeX6LCsCFe"
   },
   "source": [
    "# Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xAlFzQclsCFf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2686,
     "status": "ok",
     "timestamp": 1532073682927,
     "user": {
      "displayName": "MSRI DeepLearn",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105243882236575703967"
     },
     "user_tz": 420
    },
    "id": "pRgyL85osCFh",
    "outputId": "b1885f52-e1c1-4b46-dfe6-b602e2c34092"
   },
   "outputs": [],
   "source": [
    "transform=transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,)) ]) #,transforms.Normalize((0.1307,), (0.3081,)) using to Normalize doesn't help accuracy it seems.\n",
    "\n",
    "# Load and transform data\n",
    "trainset = torchvision.datasets.MNIST('/tmp', train=True, download=False, transform=transform)\n",
    "testset = torchvision.datasets.MNIST('/tmp', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6avkhDtssCFk"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k8JvqklasCFm"
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader,num_epochs,model,optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()# model is ready to have weights updated\n",
    "        for i, (images,labels ) in enumerate(train_loader):\n",
    "            #print(images.shape[2]*images.shape[3]) \n",
    "            images = images.view(-1,images.shape[2]*images.shape[3]) # making into a column vector\n",
    "            images = Variable(images, requires_grad=False).to(device)#.cuda()\n",
    "            labels = Variable(labels, requires_grad=False).to(device)#.cuda()\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            # Forward + Backaward + Optimization\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(images)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(y_hat,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YBb84YOMsCFp"
   },
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in dataloader:\n",
    "        images = Variable(images.view(-1, 28*28)).to(device)#.cuda()\n",
    "        labels = Variable(labels).to(device)#.cuda()\n",
    "       \n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)# gives maxes and indices locations\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).cpu().sum() \n",
    "    return 100 *correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FMtTzejdsCF1"
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model,num_epochs,optimizer,dataloader,isTrain=True):\n",
    "    \"\"\"\n",
    "    This function trains and then immediately evaluates the model \n",
    "    on the MNIST database.\n",
    "    \"\"\"\n",
    "    if isTrain:\n",
    "        train_model(trainloader,num_epochs,model,optimizer)\n",
    "    accuracy = model_accuracy_loss(model,dataloader)\n",
    "    \n",
    "    return float(accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g5eBcWd3sCF4"
   },
   "outputs": [],
   "source": [
    "def run_experiment(activation_fns, num_epochs, num_runs, activation_acc_results,activation_names ,dataloader,isTrain=True):\n",
    "    # Our constant structure :\n",
    "    # Input: 784 Neurons\n",
    "    # H1 : 256\n",
    "    # H2 : 128\n",
    "    # Output : 10\n",
    "    for run in range(num_runs):\n",
    "        if run%5==0:\n",
    "              print(\"Run: \"+str(run)+\" Epoch: \"+str(num_epochs))\n",
    "        for i in range(len(activation_names)):\n",
    "            act_name = activation_names[i]\n",
    "            experiment_model = create_swish_model(256,128,activation_fns[act_name])\n",
    "            if isTrain:\n",
    "                experiment_model.load_state_dict(torch.load('experiment weights/experiment_model_'+str(run)))\n",
    "            else:\n",
    "                experiment_model.load_state_dict(torch.load('trained weights/'+act_name+'experiment_model_'+str(run)+str(num_epochs)))\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                experiment_model.cuda()\n",
    "                \n",
    "            #Hyper Params constant for this experiment\n",
    "            learning_rate = 0.01\n",
    "            optimizer = torch.optim.Adam(experiment_model.parameters(), lr=learning_rate)\n",
    "            acc = train_and_eval(experiment_model,num_epochs,optimizer,dataloader,isTrain)\n",
    "            torch.save(experiment_model.state_dict(), 'trained weights/'+act_name+'experiment_model_'+str(run)+str(num_epochs))\n",
    "            activation_acc_results[act_name].append(acc)\n",
    "    return activation_acc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qUpZsllxsCGe"
   },
   "source": [
    "# Creating a Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(H1,H2,activation):\n",
    "    model = nn.Sequential(nn.Linear(28*28,H1,bias=False),\n",
    "                               activation(),\n",
    "                              nn.Linear(H1,H2,bias=False),\n",
    "                              activation(),\n",
    "                               nn.Linear(H2,10,bias=False))\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if matrix is symmetric\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "    * Create a model\n",
    "    * Get that model's weights\n",
    "    * for each node in the network, get the weights associated with it. (We are ignoring the biases atm)\n",
    "    * put (1-weights) into the weight matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jtBlUOeysCGf"
   },
   "outputs": [],
   "source": [
    "number_of_epochs = [1,5]\n",
    "num_runs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6574873,
     "status": "error",
     "timestamp": 1532080384068,
     "user": {
      "displayName": "MSRI DeepLearn",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105243882236575703967"
     },
     "user_tz": 420
    },
    "id": "ACOU3k-VsCGi",
    "outputId": "62fdce29-b69e-4632-8203-a8eadae1537d"
   },
   "outputs": [],
   "source": [
    "first_layer_dim = 256#10\n",
    "second_layer_dim = 128#8\n",
    "model = create_model(first_layer_dim,second_layer_dim,nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create initial distance matrix for a vanilla neural network\n",
    "def make_dist_mat(model,output_dims):\n",
    "    dims = 0\n",
    "    for name,param in model.named_parameters():\n",
    "        dims+=param.detach().numpy().shape[1]\n",
    "    dims+= output_dims\n",
    "    distance_mat = np.zeros((dims,dims))\n",
    "    distance_mat += 2.# setting large distance\n",
    "    # setting diagonal to 0\n",
    "    for i in range(len(distance_mat)):\n",
    "        distance_mat[i,i] = 0.\n",
    "    return distance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_parameters(model):\n",
    "    # we do 1-weights ,since some weights are negative. We do this to keep all weights within the range \n",
    "    # 1~2.\n",
    "    parameters = [] \n",
    "    for name,param in model.named_parameters():\n",
    "        parameters.append(1-param.detach().numpy())\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build distance matrix based on model parameters.\n",
    "def build_dist_mat(dist_mat, params, inp_dim, sec_dim, third_dim, out_dim):\n",
    "    first_zero_blocks = inp_dim\n",
    "    \n",
    "    #1st layer by column\n",
    "    layer_1_dim = params[0].shape#(256,784)\n",
    "    # (num neurons current layer, cur num neurons+num neurons next layer)\n",
    "    dist_mat[first_zero_blocks:first_zero_blocks+layer_1_dim[0], \n",
    "                 :layer_1_dim[1]] = params[0]\n",
    "    \n",
    "    # 2nd layer by column\n",
    "    second_zero_blocks = sec_dim#(256,256)\n",
    "    layer_2_dim = parameters[1].shape\n",
    "    dist_mat[:first_zero_blocks, \n",
    "                  first_zero_blocks:layer_1_dim[0]+first_zero_blocks] = params[0].T\n",
    "\n",
    "    dist_mat[first_zero_blocks+layer_1_dim[0]:first_zero_blocks+layer_1_dim[0]+layer_2_dim[0]\n",
    "             ,first_zero_blocks:layer_1_dim[0]+first_zero_blocks] = params[1]\n",
    "    \n",
    "    # 3rd layer by column\n",
    "    third_zero_blocks = third_dim #(128,128) these zero matricies should be square\n",
    "    layer_3_dim = parameters[2].shape\n",
    "    dist_mat[first_zero_blocks:first_zero_blocks+layer_2_dim[1], \n",
    "                 first_zero_blocks+second_zero_blocks:first_zero_blocks\n",
    "                 +second_zero_blocks+third_zero_blocks] = params[1].T\n",
    "\n",
    "    dist_mat[first_zero_blocks+second_zero_blocks+third_zero_blocks:,\n",
    "                first_zero_blocks+second_zero_blocks:\n",
    "                 first_zero_blocks+second_zero_blocks+third_zero_blocks] = params[2]\n",
    "    # 4th layer by column\n",
    "    fourth_zero_blocks = out_dim\n",
    "    dist_mat[first_zero_blocks+second_zero_blocks:first_zero_blocks\n",
    "                 +second_zero_blocks+third_zero_blocks,\n",
    "                 first_zero_blocks\n",
    "                 +second_zero_blocks+third_zero_blocks:] = params[2].T\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 2., ..., 2., 2., 2.],\n",
       "       [2., 0., 2., ..., 2., 2., 2.],\n",
       "       [2., 2., 0., ..., 2., 2., 2.],\n",
       "       ...,\n",
       "       [2., 2., 2., ..., 0., 2., 2.],\n",
       "       [2., 2., 2., ..., 2., 0., 2.],\n",
       "       [2., 2., 2., ..., 2., 2., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_mat = make_dist_mat(model,10)\n",
    "distance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = weight_parameters(model)\n",
    "distance_mat = build_dist_mat(distance_mat,parameters,784,first_layer_dim,second_layer_dim,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(distance_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non trained Persistence Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model_accuracy_loss(model,testloader))\n",
    "print(check_symmetric(distance_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_train_diagram = r.fit_transform(distance_mat,distance_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plot(not_train_diagram, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train a model then persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = create_model(first_layer_dim,second_layer_dim,nn.ReLU)\n",
    "optimizer = optim.Adam(trained_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before train\n",
    "model_accuracy_loss(trained_model,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_eval(trained_model,1,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(95)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy_loss(trained_model,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distance_mat = make_dist_mat(trained_model,10)\n",
    "parameters = weight_parameters(trained_model)\n",
    "train_distance_mat = build_dist_mat(train_distance_mat,parameters,784,first_layer_dim,second_layer_dim,10)\n",
    "train_distance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distance_mat[785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(train_distance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_symmetric(train_distance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = r.fit_transform(train_distance_mat, distance_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.plot(train_pd, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.bottleneck(train_pd[0], not_train_diagram[0]) #H_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.bottleneck(train_pd[1], not_train_diagram[1]) #H_1 distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path homology for direct graph homology\n",
    "# directed clique homology no software avail\n",
    "# can look at homology fluctates per epoch\n",
    "# find bottleneck distance"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MNIST MLP, Swish Experiments NO NOISE.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
