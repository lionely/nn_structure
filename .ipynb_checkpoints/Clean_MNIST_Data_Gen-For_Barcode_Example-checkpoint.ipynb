{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QIfQ6vcSsCFU"
   },
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "l0cm2wFgsCFZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ripser import Rips\n",
    "import persim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVxeX6LCsCFe"
   },
   "source": [
    "# Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xAlFzQclsCFf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2686,
     "status": "ok",
     "timestamp": 1532073682927,
     "user": {
      "displayName": "MSRI DeepLearn",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105243882236575703967"
     },
     "user_tz": 420
    },
    "id": "pRgyL85osCFh",
    "outputId": "b1885f52-e1c1-4b46-dfe6-b602e2c34092"
   },
   "outputs": [],
   "source": [
    "transform=transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,)) ]) #,transforms.Normalize((0.1307,), (0.3081,)) using to Normalize doesn't help accuracy it seems.\n",
    "\n",
    "# Load and transform data\n",
    "trainset = torchvision.datasets.MNIST('/tmp', train=True, download=False, transform=transform)\n",
    "testset = torchvision.datasets.MNIST('/tmp', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6avkhDtssCFk"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=32)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k8JvqklasCFm"
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader,num_epochs,model,optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()# model is ready to have weights updated\n",
    "        for i, (images,labels ) in enumerate(train_loader):\n",
    "            #print(images.shape[2]*images.shape[3]) \n",
    "            images = images.view(-1,images.shape[2]*images.shape[3]) # making into a column vector\n",
    "            images = Variable(images, requires_grad=False).to(device)#.cuda()\n",
    "            \n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            labels = Variable(labels, requires_grad=False).to(device)#.cuda()\n",
    "            # Forward + Backaward + Optimization\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(images)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(y_hat,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YBb84YOMsCFp"
   },
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in dataloader:\n",
    "        images = Variable(images.view(-1, 28*28)).to(device)#.cuda()\n",
    "        labels = Variable(labels).to(device)#.cuda()\n",
    "       \n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)# gives maxes and indices locations\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).cpu().sum() \n",
    "    return 100 *correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FMtTzejdsCF1"
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model,num_epochs,optimizer,dataloader,isTrain=True):\n",
    "    \"\"\"\n",
    "    This function trains and then immediately evaluates the model \n",
    "    on the MNIST database.\n",
    "    \"\"\"\n",
    "    if isTrain:\n",
    "        train_model(trainloader,num_epochs,model,optimizer)\n",
    "    accuracy = model_accuracy_loss(model,dataloader)\n",
    "    \n",
    "    return float(accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g5eBcWd3sCF4"
   },
   "outputs": [],
   "source": [
    "def run_experiment(activation_fns, num_epochs, num_runs, activation_acc_results,activation_names ,dataloader,isTrain=True):\n",
    "    # Our constant structure :\n",
    "    # Input: 784 Neurons\n",
    "    # H1 : 256\n",
    "    # H2 : 128\n",
    "    # Output : 10\n",
    "    for run in range(num_runs):\n",
    "        if run%5==0:\n",
    "              print(\"Run: \"+str(run)+\" Epoch: \"+str(num_epochs))\n",
    "        for i in range(len(activation_names)):\n",
    "            act_name = activation_names[i]\n",
    "            experiment_model = create_swish_model(256,128,activation_fns[act_name])\n",
    "            if isTrain:\n",
    "                experiment_model.load_state_dict(torch.load('experiment weights/experiment_model_'+str(run)))\n",
    "            else:\n",
    "                experiment_model.load_state_dict(torch.load('trained weights/'+act_name+'experiment_model_'+str(run)+str(num_epochs)))\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                experiment_model.cuda()\n",
    "                \n",
    "            #Hyper Params constant for this experiment\n",
    "            learning_rate = 0.01\n",
    "            optimizer = torch.optim.Adam(experiment_model.parameters(), lr=learning_rate)\n",
    "            acc = train_and_eval(experiment_model,num_epochs,optimizer,dataloader,isTrain)\n",
    "            torch.save(experiment_model.state_dict(), 'trained weights/'+act_name+'experiment_model_'+str(run)+str(num_epochs))\n",
    "            activation_acc_results[act_name].append(acc)\n",
    "    return activation_acc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qUpZsllxsCGe"
   },
   "source": [
    "# Creating a Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(H1,H2,activation):\n",
    "    model = nn.Sequential(nn.Linear(28*28,H1,bias=False),\n",
    "                               activation(),\n",
    "                              nn.Linear(H1,H2,bias=False),\n",
    "                              activation(),\n",
    "                               nn.Linear(H2,10,bias=False))\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if matrix is symmetric\n",
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "    * Create a model\n",
    "    * Get that model's weights\n",
    "    * for each node in the network, get the weights associated with it. (We are ignoring the biases atm)\n",
    "    * put (1-weights) into the weight matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create initial distance matrix for a vanilla neural network\n",
    "def make_dist_mat(model,output_dims):\n",
    "    dims = 0\n",
    "    for name,param in model.named_parameters():\n",
    "        dims+=param.cpu().detach().numpy().shape[1]\n",
    "    dims+= output_dims\n",
    "    distance_mat = np.zeros((dims,dims))\n",
    "    distance_mat += 2.# setting large distance\n",
    "    # setting diagonal to 0\n",
    "    for i in range(len(distance_mat)):\n",
    "        distance_mat[i,i] = 0.\n",
    "    return distance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_parameters(model):\n",
    "    # we do 1-weights ,since some weights are negative. We do this to keep all weights within the range \n",
    "    # 1~2.\n",
    "    parameters = [] \n",
    "    for name,param in model.named_parameters():\n",
    "        parameters.append(1-param.cpu().detach().numpy())\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build distance matrix based on model parameters.\n",
    "def build_dist_mat(dist_mat, params, inp_dim, sec_dim, third_dim, out_dim):\n",
    "    first_zero_blocks = inp_dim\n",
    "    \n",
    "    #1st layer by column\n",
    "    layer_1_dim = params[0].shape#(256,784)\n",
    "    # (num neurons current layer, cur num neurons+num neurons next layer)\n",
    "    dist_mat[first_zero_blocks:first_zero_blocks+layer_1_dim[0], \n",
    "                 :layer_1_dim[1]] = params[0]\n",
    "    \n",
    "    # 2nd layer by column\n",
    "    second_zero_blocks = sec_dim#(256,256)\n",
    "    layer_2_dim = parameters[1].shape\n",
    "    dist_mat[:first_zero_blocks, \n",
    "                  first_zero_blocks:layer_1_dim[0]+first_zero_blocks] = params[0].T\n",
    "\n",
    "    dist_mat[first_zero_blocks+layer_1_dim[0]:first_zero_blocks+layer_1_dim[0]+layer_2_dim[0]\n",
    "             ,first_zero_blocks:layer_1_dim[0]+first_zero_blocks] = params[1]\n",
    "    \n",
    "    # 3rd layer by column\n",
    "    third_zero_blocks = third_dim #(128,128) these zero matricies should be square\n",
    "    layer_3_dim = parameters[2].shape\n",
    "    dist_mat[first_zero_blocks:first_zero_blocks+layer_2_dim[1], \n",
    "                 first_zero_blocks+second_zero_blocks:first_zero_blocks\n",
    "                 +second_zero_blocks+third_zero_blocks] = params[1].T\n",
    "\n",
    "    dist_mat[first_zero_blocks+second_zero_blocks+third_zero_blocks:,\n",
    "                first_zero_blocks+second_zero_blocks:\n",
    "                 first_zero_blocks+second_zero_blocks+third_zero_blocks] = params[2]\n",
    "    # 4th layer by column\n",
    "    fourth_zero_blocks = out_dim\n",
    "    dist_mat[first_zero_blocks+second_zero_blocks:first_zero_blocks\n",
    "                 +second_zero_blocks+third_zero_blocks,\n",
    "                 first_zero_blocks\n",
    "                 +second_zero_blocks+third_zero_blocks:] = params[2].T\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Distance Matricies and PD intervals to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rips(maxdim=1, thresh=inf, coeff=2, do_cocycles=False, n_perm = None, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "num_models = 1\n",
    "num_epochs = 5#n-1\n",
    "first_layer_dim = 256#10\n",
    "second_layer_dim = 128#8\n",
    "model_performances = {}\n",
    "r = Rips(maxdim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Experiment Time: 1.1713844855626425 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(num_models):\n",
    "    name = 'model_'+str(i)+'_ne-'+str(0)\n",
    "    PATH = 'experiment_data/model_params/'+'model_'+str(i)\n",
    "    model = create_model(first_layer_dim,second_layer_dim,nn.ReLU)\n",
    "    #torch.save(model.state_dict(), PATH)\n",
    "    \n",
    "    distance_mat = make_dist_mat(model,10)# 10 = out_dim\n",
    "    parameters = weight_parameters(model)\n",
    "    distance_mat = build_dist_mat(distance_mat,parameters,784,first_layer_dim,second_layer_dim,10)\n",
    "    \n",
    "    #accuracy before training\n",
    "    #model_performances[name] = [model_accuracy_loss(model,testloader).item()]\n",
    "    #save dist_mat before training\n",
    "    #np.savez('experiment_data/barcode_examples/distance_matricies/not-trained/dist_mat-'+name, dist_mat=distance_mat)\n",
    "    \n",
    "    #saving pd diagram\n",
    "    if check_symmetric(distance_mat): \n",
    "        not_train_diagram = r.fit_transform(distance_mat,distance_matrix=True)\n",
    "        #np.savez('experiment_data/barcode_examples/pd_intervals/not-trained/pd-'+name, pd=not_train_diagram)\n",
    "    \n",
    "#     for e in range(num_epochs-1,num_epochs):\n",
    "#         model.load_state_dict(torch.load(PATH))\n",
    "#         name = 'model_'+str(i)+'_ne-'+str(e+1) # name after training\n",
    "#         # now train the model\n",
    "#         optimizer = optim.Adam(model.parameters())\n",
    "#         train_and_eval(model,e+1,optimizer,trainloader)\n",
    "#         #performance after training\n",
    "#         model_performances[name] = [model_accuracy_loss(model,testloader).item()]\n",
    "        \n",
    "#         #new dist mat after training\n",
    "#         parameters = weight_parameters(model)\n",
    "#         distance_mat = build_dist_mat(distance_mat,parameters,784,first_layer_dim,second_layer_dim,10)\n",
    "#         #save dist_mat after training\n",
    "#         np.savez('experiment_data/barcode_examples/distance_matricies/trained/dist_mat-'+name, dist_mat=distance_mat)\n",
    "#         #saving pd diagram\n",
    "#         if check_symmetric(distance_mat): \n",
    "#             train_diagram = r.fit_transform(distance_mat,distance_matrix=True)\n",
    "#             np.savez('experiment_data/barcode_examples/pd_intervals/trained/pd-'+name, pd=train_diagram)\n",
    "end = time.time()\n",
    "print(\"Elapsed Experiment Time: \"+str((end-start)/60.)+\" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.9121328 ],\n",
       "       [0.        , 0.91220409],\n",
       "       [0.        , 0.91236806],\n",
       "       ...,\n",
       "       [0.        , 0.96581131],\n",
       "       [0.        , 0.96623284],\n",
       "       [0.        ,        inf]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_train_diagram[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.plot(not_train_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Should also record accuracy for each network before and after training and \n",
    "#how many epochs a model was training for\n",
    "#pd.DataFrame(data=model_performances,index=['Accuracy']).to_csv('experiment_data/model_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('experiment_data/barcode_examples/distance_matricies/not-trained/dist_mat',dist_mat=distance_mat)\n",
    "np.savez('experiment_data/barcode_examples/distance_matricies/trained/dist_mat',dist_mat=distance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('experiment_data/distance_matricies/not-trained/not_train_pd',pd=not_train_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_load = np.load('experiment_data/distance_matricies/not-trained/not_train_pd.npz')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "MNIST MLP, Swish Experiments NO NOISE.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
